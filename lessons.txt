
Вечерняя школа
#1
#2 ПОДЫ
https://github.com/slurm-personal/school-dev-k8s     //непонятный гит с лекциями от вечерней школы

kubectl get pod
kubectl get po //тоже самое

kubectl create -f pod.yaml (запуск ямла, ямл образец в соседнем файле)
kubectl describe po my-pod //описание пода

kubectl delete po my-pod
kubectl delete -f pod.yaml

#3 REPLICASET

kubectl delete po --all //удалит все поды
kubectl delete all --all -A //снесет все обьекты со всех нэймспэйсов //это опасно
kubectl delete replicaset --all

kubectl create -f replicaset.yaml //пременяется только один раз
kubectl apply -f replicaset.yaml  //перечитает файл применит изменения

kubectl get replicasets
kubectl get rs  //то же самое

kubectl get po -l app=my-app //поиск подов по лэйблу

kubectl scale --replicas 3 replicaset my-replicaset  //увеличение реплик вручную

kubectl set image replicaset my-replicaset nginx=nginx:1.12 // обновление образа вручную

kubectl explain <чтото>  // открывает документашку

    DEPLOYMENT
kubectl apply -f deployment.yaml
kubectl get deploy
kubectl set image deployment my-deployment '*=<image>'
kubectl edit deployment my-deployment (выводит временный файл с описанием деплоймента, после его редактирования изменения применяются но не сохраняються в файл)
kubectl rollout undo deployment my-deployment (откатит изменения, он при создании нового rs не удаляет старый а просто скелит поле replicas)
revisionHistoryLimit: 10 (глубина хранения старых репликасетов после обновлений)

kubectl explain deployment.spec.strategy (обьяснит значение этого поля)

strategy (это способ обновления: грохать сразу все старые реплики или постепенно, есть доп инфа видео №3 прим.1:08:00время)

        NAMESPACES
разделение пространства имен
могут ли одни приложения ходить в другие нэймспэийсы и многое другое зависит от политик

        RESOURCES
Limits ограничения по изпользованию приложением памяти и ядер
Requests количество ресурсов, которое резервируется для пода на ноде
QoS Class поле которое указывает важность пода, в случае если ресерсов будет не хватать, от него зависит кто первый съедет с ноды

#4 ПЕРЕМЕННЫЕ ОКРУЖЕНИЯ

kubectl apply -f configmap.yaml (конфигмап надо заапплаить)
kubectl get cm (просмотреть существующие конфигмапы)
kubectl exec -t my-deployment-7bc97c6ff4-ghvph -- env (посмотреть переменные внутри пода)

СЕКРЕТЫ

generic - пароли токены приложений
docker-registry - данные афторизации в docker registry(секретные данные ключи доступа к различным репозиториям типа git email и др.)
tls - TLS сертификаты для Ingress

kubectl create secret generic test --from-literal=test1=asdf --from-literal=dbpassword=1q2wpass123 (создаст секрет)
kubectl get secrets (выведет кол. созданных секретов без их показа)
delete --all делать не надо удаляться ключи доступа к наймспэйсам
Opaque - непрозрачный  generic==Opaque
kubectl get secrets test -o yaml (покажет ключи и значения закодированные в b64)
echo MXEyd3Bhc3MxMjM= | base64 -d (раскодирует секрет)

пересылаем файлы через переменные через конфигмап
kubectl exec -it my-deployment-5f8455c477-6d56t -- env (можно посмотреть секрет если у разработчика не отобрали exec права)
kubectl exec -it my-deployment-5db5bdc77-f4bdn -- busybox sh (можно зайти внутрь пода и просмотреть файлы)
kubectl port-forward my-deployment-5db5bdc77-f4bdn 8080:80 & (так можно постучаться на порт нжинкса) далее введем-->> curl 127.0.0.1:8080
ps ax | grep 8080   далее ->> kill -9 4023

Donward API

все поля передачи переменных заполнил в deployment.yaml

kubectl get po -o wide (более подробная инфа по подам)

#4
ХРАНЕНИЕ ДАННЫХ

HostPath
монтирует папку из ноды в реплику (образец в deployment.yaml)
обычно запрещается использование HostPath политикой безопасности во избежании доступа разработчикам к конф файлам на ноде

EmptyDir
cri создает временный диск и прокидывает его внутрь контейнера. При рестарте приложения данные сохраняются, при удалении удаляются.
kubectl exec -it my-deployment-5cc9b958f4-zw74m -- busybox sh далее->> mount (посмотреть что куда смонтировано)

PC/PVC (PersistentVolumeClaim/PersistentVolume)
Storage class хранит параметры подключения
PersistentVolumeClaim описывает требования к тому
PersistentVolume хранит параметры и статус тома
Разговор о самостоятельном создании диска на желесках или аренды в облаках
PVC делает запрос на 10GB и ему выдают диск не меньше этого размера
После этого диск переходит в состояние bound
Provisioner Create PV нарезает вольюмы согласно требования pvc, чтобы не отдавать диск на 1000Gb поду с запросом на 10Mb
kubectl apply -f pvc.yaml
много интересного, в том числе и увеличение размера диска
короче если надо покупаешь диск пересматриваешь видео

initConteiners
их может быть несколько
можно монтировать те же тома что и в основных контейнерах

ReadWriteMany
cephFS - (система хранения данных)умеет подключать несколько нод к одному диску

ReadWriteOnce
RBD винчестер умеет монтировать диск только на одну ноду
две реплики на одной ноде смогут использовать RBD и иметь доступ к диску

#5 СЕТЕВЫЕ ИНТЕРФЕЙСЫ

PROBES
Liveness Probe контроль за состоянием приложения исполняется постоянно
Readiness Probe пров. готово ли приложение принимать трафик. Исполняется постоянно. В случае неудачи убирается из баллансировки
StartUp Probe пров. запустилось ли приложение. Исполняется при старте.

SERVICES
ClusterIP внутрикластерное взаимодействие (важно совпадение селектора и лэйблов приложений)

kubectl run test --image=amouat/network-utils -it bash (небольшая утилитка для теста сетей)
kubectl exec test -it -- bash


NodePort открывает порты на нодах от 30000 до 3????
LoadBalancer работает только в облаках
ExternalName непонятно
ExternalIps на все ноды устанавливает определенный ip по которому можно попасть в поды тоже не понятно

Headless хрень какаято, в основном применяеться со stateful сервисами


